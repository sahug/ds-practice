{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenVaccine - COVID-19 mRNA Vaccine Degradation Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this competition, you will be predicting the degradation rates at various locations along RNA sequence.\n",
    "\n",
    "There are multiple ground truth values provided in the training data. While the submission format requires all 5 to be predicted, only the following are scored: reactivity, deg_Mg_pH10, and deg_Mg_50C.\n",
    "\n",
    "#### Files\n",
    " - `train.json` - the training data\n",
    " - `test.json` - the test set, without any columns associated with the ground truth.\n",
    " - `sample_submission.csv` - a sample submission file in the correct format\n",
    "\n",
    "#### Columns\n",
    " - `id` - An arbitrary identifier for each sample.\n",
    " \n",
    " \n",
    " - `seq_scored` - `(68 in Train and Public Test, 91 in Private Test)` Integer value denoting the number of positions used in scoring with predicted values. This should match the length of `reactivity, deg_* and *_error_*` columns. Note that molecules used for the Private Test will be longer than those in the Train and Public Test data, so the size of this vector will be different.\n",
    " \n",
    " \n",
    " - `seq_length` - `(107 in Train and Public Test, 130 in Private Test)` Integer values, denotes the length of sequence. `Note that molecules used for the Private Test will be longer than those in the Train and Public Test data, so the size of this vector will be different`.\n",
    " \n",
    " \n",
    " - `sequence` - `(1x107 string in Train and Public Test, 130 in Private Test)` Describes the RNA sequence, a combination of `A, G, U, and C` for each sample. Should be 107 characters long, and the first 68 bases should correspond to the 68 positions specified in `seq_scored` (note: indexed starting at 0).\n",
    " \n",
    " \n",
    " - `structure` - `(1x107 string in Train and Public Test, 130 in Private Test)` An array of `(, ), and .` characters that describe whether a base is estimated to be paired or unpaired. Paired bases are denoted by opening and closing parentheses `e.g. (....) means that base 0 is paired to base 5, and bases 1-4 are unpaired`.\n",
    " \n",
    " \n",
    " - `reactivity` - `(1x68 vector in Train and Public Test, 1x91 in Private Test)` An array of floating point numbers, should have the same length as `seq_scored`. These numbers are reactivity values for the first 68 bases as denoted in sequence, and used to determine the likely secondary structure of the RNA sample.\n",
    " \n",
    " \n",
    " - `deg_pH10` - `(1x68 vector in Train and Public Test, 1x91 in Private Test)` An array of floating point numbers, should have the same length as `seq_scored`. These numbers are reactivity values for the first 68 bases as denoted in sequence, and used to determine the likelihood of degradation at the base/linkage after incubating without magnesium at high pH (pH 10).\n",
    " \n",
    " \n",
    " - `deg_Mg_pH10` - `(1x68 vector in Train and Public Test, 1x91 in Private Test)` An array of floating point numbers, should have the same length as seq_scored. These numbers are reactivity values for the first 68 bases as denoted in sequence, and used to determine the likelihood of degradation at the base/linkage after incubating with magnesium in high pH (pH 10).\n",
    " \n",
    " \n",
    " - `deg_50C` - `(1x68 vector in Train and Public Test, 1x91 in Private Test)` An array of floating point numbers, should have the same length as `seq_scored`. These numbers are reactivity values for the first 68 bases as denoted in `sequence`, and used to determine the likelihood of degradation at the base/linkage after incubating without magnesium at high temperature (50 degrees Celsius).\n",
    " \n",
    " \n",
    " - `deg_Mg_50C` - `(1x68 vector in Train and Public Test, 1x91 in Private Test)` An array of floating point numbers, should have the same length as `seq_scored`. These numbers are reactivity values for the first 68 bases as denoted in sequence, and used to determine the likelihood of degradation at the base/linkage after incubating with magnesium at high temperature (50 degrees Celsius).\n",
    " \n",
    " \n",
    " - `*_error_*` - An array of floating point numbers, should have the same length as the corresponding reactivity or `deg_* `columns, calculated errors in experimental values obtained in reactivity and `deg_*` columns.\n",
    " \n",
    " \n",
    " - `predicted_loop_type` - `(1x107 string)` Describes the structural context `(also referred to as loop type)` of each character in sequence. Loop types assigned by `bpRNA` from `Vienna RNAfold` 2 structure. \n",
    " \n",
    " From the `bpRNA_documentation`:   \n",
    " \n",
    "  - `S`: paired \"Stem\" \n",
    "  - `M`: Multiloop \n",
    "  - `I`: Internal loop \n",
    "  - `B`: Bulge \n",
    "  - `H`: Hairpin loop \n",
    "  - `E`: dangling End \n",
    "  - `X`: eXternal loop\n",
    "  - `S/N` filter Indicates if the sample passed filters described below in Additional Notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional Notes\n",
    "At the beginning of the competition, Stanford scientists have data on 3029 RNA `sequences` of length 107. For technical reasons, measurements cannot be carried out on the final bases of these RNA `sequences`, so we have experimental data (ground truth) in 5 conditions for the first 68 bases.\n",
    "\n",
    "We have split out 629 of these 3029 sequences for a public test set to allow for continuous evaluation through the competition, on the public leaderboard. These sequences, in `test.json`, have been additionally filtered based on three criteria detailed below to ensure that this subset is not dominated by any large cluster of RNA molecules with poor data, which might bias the public leaderboard. The remaining 2400 sequences for which we have data are in `train.json`.\n",
    "\n",
    "For our final and most important scoring (the Private Leaderbooard), Stanford scientists are carrying out measurements on 3005 new `RNAs`, which have somewhat longer lengths of 130 bases. For these data, we expect to have measurements for the first 91 bases, again missing the ends of the RNA. These sequences constitute another 3005 of the 3634 sequences in `test.json`.\n",
    "\n",
    "For those interested in how the 629 107-base sequences in `test.json` were filtered, here were the steps to ensure a diverse and high quality test set for public leaderboard scoring:\n",
    "\n",
    "Minimum value across all 5 conditions must be greater than -0.5.\n",
    "\n",
    "Mean signal/noise across all 5 conditions must be greater than 1.0. [Signal/noise is defined as mean( measurement value over 68 nts )/mean( statistical error in measurement value over 68 nts)]\n",
    "\n",
    "To help ensure sequence diversity, the resulting sequences were clustered into clusters with less than 50% sequence similarity, and the 629 test set sequences were chosen from clusters with 3 or fewer members. That is, any sequence in the test set should be sequence similar to at most 2 other `sequences`.\n",
    "\n",
    "Note that these filters have not been applied to the 2400 RNAs in the public training data `train.json` â€” some of those measurements have negative values or poor `signal-to-noise`, or some `RNA` sequences have near-identical sequences in that set. But we are providing all those data in case competitors can squeeze out more signal.\n",
    "\n",
    "After discussion, the three filters noted above will be applied to Private Test on 3005 sequences, and predictions on sequences that do not pass the filters will not be included in scoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Scheme\n",
    "(1) train denoising auto encoder model using all data including train and test data\n",
    "\n",
    "(2) from the weights of denoising auto encoder model, finetune to predict targets such as reactivity\n",
    "rough network architecture\n",
    "\n",
    "`inputs -> conv1ds -> aggregation of neighborhoods -> multi head attention -> aggregation of neighborhoods -> multi head attention -> conv1d -> predict`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_dir = None # model dir for resuming training. if None, train from scrach\n",
    "\n",
    "one_fold = False # if True, train model at only first fold. use if you try a new idea quickly.\n",
    "run_test = False # if True, use small data. you can check whether this code run or not\n",
    "denoise = True # if True, use train data whose signal_to_noise > 1\n",
    "\n",
    "ae_epochs = 20 # epoch of training of denoising auto encoder\n",
    "ae_epochs_each = 5 # epoch of training of denoising auto encoder each time. \n",
    "                   # I use train data (seqlen = 107) and private test data (seqlen = 130) for auto encoder training.\n",
    "                   # I dont know how to easily fit keras model to use both of different shape data simultaneously, \n",
    "                   # so I call fit function several times. \n",
    "ae_batch_size = 32\n",
    "\n",
    "epochs_list = [30, 10, 3, 3, 5, 5]\n",
    "batch_size_list = [8, 16, 32, 64, 128, 256] \n",
    "\n",
    "## copy pretrain model to working dir\n",
    "import shutil\n",
    "import glob\n",
    "if pretrain_dir is not None:\n",
    "    for d in glob.glob(pretrain_dir + \"*\"):\n",
    "        shutil.copy(d, \".\")\n",
    "    \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import gc\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4edfa399e1e44638a766db0c0019f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2096.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4a69803e4d42ce846e3f08250b444b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=629.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fca7e2d574640b9b96f617047fc937d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3005.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "train = pd.read_json(\"data/stanford-covid-vaccine/train.json\",lines=True)\n",
    "if denoise:\n",
    "    train = train[train.signal_to_noise > 1].reset_index(drop = True)\n",
    "test  = pd.read_json(\"data/stanford-covid-vaccine/test.json\",lines=True)\n",
    "test_pub = test[test[\"seq_length\"] == 107]\n",
    "test_pri = test[test[\"seq_length\"] == 130]\n",
    "sub = pd.read_csv(\"data/stanford-covid-vaccine/sample_submission.csv\")\n",
    "\n",
    "if run_test: ## to test \n",
    "    train = train[:30]\n",
    "    test_pub = test_pub[:30]\n",
    "    test_pri = test_pri[:30]\n",
    "\n",
    "As = []\n",
    "\n",
    "for id in tqdm(train[\"id\"]):\n",
    "    a = np.load(f\"data/stanford-covid-vaccine/bpps/{id}.npy\")\n",
    "    As.append(a)\n",
    "\n",
    "As = np.array(As)\n",
    "\n",
    "As_pub = []\n",
    "\n",
    "for id in tqdm(test_pub[\"id\"]):\n",
    "    a = np.load(f\"data/stanford-covid-vaccine/bpps/{id}.npy\")\n",
    "    As_pub.append(a)\n",
    "\n",
    "As_pub = np.array(As_pub)\n",
    "\n",
    "As_pri = []\n",
    "\n",
    "for id in tqdm(test_pri[\"id\"]):\n",
    "    a = np.load(f\"data/stanford-covid-vaccine/bpps/{id}.npy\")\n",
    "    As_pri.append(a)\n",
    "    \n",
    "As_pri = np.array(As_pri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2096, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>structure</th>\n",
       "      <th>predicted_loop_type</th>\n",
       "      <th>signal_to_noise</th>\n",
       "      <th>SN_filter</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>seq_scored</th>\n",
       "      <th>reactivity_error</th>\n",
       "      <th>deg_error_Mg_pH10</th>\n",
       "      <th>deg_error_pH10</th>\n",
       "      <th>deg_error_Mg_50C</th>\n",
       "      <th>deg_error_50C</th>\n",
       "      <th>reactivity</th>\n",
       "      <th>deg_Mg_pH10</th>\n",
       "      <th>deg_pH10</th>\n",
       "      <th>deg_Mg_50C</th>\n",
       "      <th>deg_50C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>id_001f94081</td>\n",
       "      <td>GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...</td>\n",
       "      <td>.....((((((.......)))).)).((.....((..((((((......</td>\n",
       "      <td>EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...</td>\n",
       "      <td>6.894</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.1359, 0.20700000000000002, 0.1633, 0.1452, ...</td>\n",
       "      <td>[0.26130000000000003, 0.38420000000000004, 0.1...</td>\n",
       "      <td>[0.2631, 0.28600000000000003, 0.0964, 0.1574, ...</td>\n",
       "      <td>[0.1501, 0.275, 0.0947, 0.18660000000000002, 0...</td>\n",
       "      <td>[0.2167, 0.34750000000000003, 0.188, 0.2124, 0...</td>\n",
       "      <td>[0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...</td>\n",
       "      <td>[0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...</td>\n",
       "      <td>[2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...</td>\n",
       "      <td>[0.35810000000000003, 2.9683, 0.2589, 1.4552, ...</td>\n",
       "      <td>[0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>id_006f36f57</td>\n",
       "      <td>GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...</td>\n",
       "      <td>.....((((.((.....((((.(((.....)))..((((......)...</td>\n",
       "      <td>EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...</td>\n",
       "      <td>8.800</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.0931, 0.13290000000000002, 0.11280000000000...</td>\n",
       "      <td>[0.1365, 0.2237, 0.1812, 0.1333, 0.1148, 0.160...</td>\n",
       "      <td>[0.17020000000000002, 0.178, 0.111, 0.091, 0.0...</td>\n",
       "      <td>[0.1033, 0.1464, 0.1126, 0.09620000000000001, ...</td>\n",
       "      <td>[0.14980000000000002, 0.1761, 0.1517, 0.116700...</td>\n",
       "      <td>[0.44820000000000004, 1.4822, 1.1819, 0.743400...</td>\n",
       "      <td>[0.2504, 1.4021, 0.9804, 0.49670000000000003, ...</td>\n",
       "      <td>[2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...</td>\n",
       "      <td>[0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...</td>\n",
       "      <td>[0.9501000000000001, 1.7974999999999999, 1.499...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>id_00ab2d761</td>\n",
       "      <td>GGAAAGCGCCGCGGCGGUAGCGGCAGCGAGGAGCGCUACCAAGGCA...</td>\n",
       "      <td>.....(.(((((.(((((((((...........)))))))..(((....</td>\n",
       "      <td>EEEEESISSSSSISSSSSSSSSHHHHHHHHHHHSSSSSSSMMSSSH...</td>\n",
       "      <td>4.136</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.1942, 0.2041, 0.1626, 0.1213, 0.10590000000...</td>\n",
       "      <td>[0.2726, 0.2984, 0.21660000000000001, 0.1637, ...</td>\n",
       "      <td>[0.3393, 0.2728, 0.2005, 0.1703, 0.1495, 0.134...</td>\n",
       "      <td>[0.165, 0.20520000000000002, 0.179, 0.1333, 0....</td>\n",
       "      <td>[0.2864, 0.24710000000000001, 0.2222, 0.1903, ...</td>\n",
       "      <td>[0.7642, 1.6641, 1.0622, 0.5008, 0.4107, 0.133...</td>\n",
       "      <td>[0.9559000000000001, 1.9442, 1.0114, 0.5105000...</td>\n",
       "      <td>[1.9554, 2.1298, 1.0403, 0.609, 0.5486, 0.386,...</td>\n",
       "      <td>[0.22460000000000002, 1.7281, 1.381, 0.6623, 0...</td>\n",
       "      <td>[0.5882000000000001, 1.1786, 0.9704, 0.6035, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>id_00abef1d7</td>\n",
       "      <td>GGAAAACAAUUGCAUCGUUAGUACGACUCCACAGCGUAAGCUGUGG...</td>\n",
       "      <td>.........((((((((......((((((((((((....)))))))...</td>\n",
       "      <td>EEEEEEEEESSSSSSSSIIIIIISSSSSSSSSSSSHHHHSSSSSSS...</td>\n",
       "      <td>2.485</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.422, 0.5478000000000001, 0.4749000000000000...</td>\n",
       "      <td>[0.4801, 0.7943, 0.42160000000000003, 0.397300...</td>\n",
       "      <td>[0.9822000000000001, 1.272, 0.6940000000000001...</td>\n",
       "      <td>[0.5827, 0.7555000000000001, 0.5949, 0.4511, 0...</td>\n",
       "      <td>[0.9306000000000001, 1.0496, 0.5844, 0.7796000...</td>\n",
       "      <td>[0.895, 2.3377, 2.2305, 2.003, 1.9006, 1.0373,...</td>\n",
       "      <td>[0.46040000000000003, 3.6695, 0.78550000000000...</td>\n",
       "      <td>[2.7711, 7.365, 1.6924000000000001, 1.43840000...</td>\n",
       "      <td>[1.073, 2.8604000000000003, 1.9936, 1.0273, 1....</td>\n",
       "      <td>[2.0964, 3.3688000000000002, 0.6399, 2.1053, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>id_00b436dec</td>\n",
       "      <td>GGAAAUCAUCGAGGACGGGUCCGUUCAGCACGCGAAAGCGUCGUGA...</td>\n",
       "      <td>.....(((((((((((..(((((((((..((((....))))..)))...</td>\n",
       "      <td>EEEEESSSSSSSSSSSIISSSSSSSSSIISSSSHHHHSSSSIISSS...</td>\n",
       "      <td>1.727</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.4843, 0.5233, 0.4554, 0.43520000000000003, ...</td>\n",
       "      <td>[0.8719, 1.0307, 0.6649, 0.34500000000000003, ...</td>\n",
       "      <td>[0.7045, 0.7775000000000001, 0.5662, 0.4561, 0...</td>\n",
       "      <td>[0.384, 0.723, 0.4766, 0.30260000000000004, 0....</td>\n",
       "      <td>[0.7429, 0.9137000000000001, 0.480400000000000...</td>\n",
       "      <td>[1.1576, 1.5137, 1.3382, 1.5622, 1.2121, 0.295...</td>\n",
       "      <td>[1.6912, 5.2652, 2.3901, 0.45890000000000003, ...</td>\n",
       "      <td>[1.8641, 2.3767, 1.149, 1.0132, 0.9876, 0.0, 0...</td>\n",
       "      <td>[0.49060000000000004, 4.6339, 1.95860000000000...</td>\n",
       "      <td>[1.2852000000000001, 2.5460000000000003, 0.234...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index            id                                           sequence  \\\n",
       "0      0  id_001f94081  GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...   \n",
       "1      2  id_006f36f57  GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...   \n",
       "2      5  id_00ab2d761  GGAAAGCGCCGCGGCGGUAGCGGCAGCGAGGAGCGCUACCAAGGCA...   \n",
       "3      6  id_00abef1d7  GGAAAACAAUUGCAUCGUUAGUACGACUCCACAGCGUAAGCUGUGG...   \n",
       "4      7  id_00b436dec  GGAAAUCAUCGAGGACGGGUCCGUUCAGCACGCGAAAGCGUCGUGA...   \n",
       "\n",
       "                                           structure  \\\n",
       "0  .....((((((.......)))).)).((.....((..((((((......   \n",
       "1  .....((((.((.....((((.(((.....)))..((((......)...   \n",
       "2  .....(.(((((.(((((((((...........)))))))..(((....   \n",
       "3  .........((((((((......((((((((((((....)))))))...   \n",
       "4  .....(((((((((((..(((((((((..((((....))))..)))...   \n",
       "\n",
       "                                 predicted_loop_type  signal_to_noise  \\\n",
       "0  EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...            6.894   \n",
       "1  EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...            8.800   \n",
       "2  EEEEESISSSSSISSSSSSSSSHHHHHHHHHHHSSSSSSSMMSSSH...            4.136   \n",
       "3  EEEEEEEEESSSSSSSSIIIIIISSSSSSSSSSSSHHHHSSSSSSS...            2.485   \n",
       "4  EEEEESSSSSSSSSSSIISSSSSSSSSIISSSSHHHHSSSSIISSS...            1.727   \n",
       "\n",
       "   SN_filter  seq_length  seq_scored  \\\n",
       "0          1         107          68   \n",
       "1          1         107          68   \n",
       "2          1         107          68   \n",
       "3          1         107          68   \n",
       "4          1         107          68   \n",
       "\n",
       "                                    reactivity_error  \\\n",
       "0  [0.1359, 0.20700000000000002, 0.1633, 0.1452, ...   \n",
       "1  [0.0931, 0.13290000000000002, 0.11280000000000...   \n",
       "2  [0.1942, 0.2041, 0.1626, 0.1213, 0.10590000000...   \n",
       "3  [0.422, 0.5478000000000001, 0.4749000000000000...   \n",
       "4  [0.4843, 0.5233, 0.4554, 0.43520000000000003, ...   \n",
       "\n",
       "                                   deg_error_Mg_pH10  \\\n",
       "0  [0.26130000000000003, 0.38420000000000004, 0.1...   \n",
       "1  [0.1365, 0.2237, 0.1812, 0.1333, 0.1148, 0.160...   \n",
       "2  [0.2726, 0.2984, 0.21660000000000001, 0.1637, ...   \n",
       "3  [0.4801, 0.7943, 0.42160000000000003, 0.397300...   \n",
       "4  [0.8719, 1.0307, 0.6649, 0.34500000000000003, ...   \n",
       "\n",
       "                                      deg_error_pH10  \\\n",
       "0  [0.2631, 0.28600000000000003, 0.0964, 0.1574, ...   \n",
       "1  [0.17020000000000002, 0.178, 0.111, 0.091, 0.0...   \n",
       "2  [0.3393, 0.2728, 0.2005, 0.1703, 0.1495, 0.134...   \n",
       "3  [0.9822000000000001, 1.272, 0.6940000000000001...   \n",
       "4  [0.7045, 0.7775000000000001, 0.5662, 0.4561, 0...   \n",
       "\n",
       "                                    deg_error_Mg_50C  \\\n",
       "0  [0.1501, 0.275, 0.0947, 0.18660000000000002, 0...   \n",
       "1  [0.1033, 0.1464, 0.1126, 0.09620000000000001, ...   \n",
       "2  [0.165, 0.20520000000000002, 0.179, 0.1333, 0....   \n",
       "3  [0.5827, 0.7555000000000001, 0.5949, 0.4511, 0...   \n",
       "4  [0.384, 0.723, 0.4766, 0.30260000000000004, 0....   \n",
       "\n",
       "                                       deg_error_50C  \\\n",
       "0  [0.2167, 0.34750000000000003, 0.188, 0.2124, 0...   \n",
       "1  [0.14980000000000002, 0.1761, 0.1517, 0.116700...   \n",
       "2  [0.2864, 0.24710000000000001, 0.2222, 0.1903, ...   \n",
       "3  [0.9306000000000001, 1.0496, 0.5844, 0.7796000...   \n",
       "4  [0.7429, 0.9137000000000001, 0.480400000000000...   \n",
       "\n",
       "                                          reactivity  \\\n",
       "0  [0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...   \n",
       "1  [0.44820000000000004, 1.4822, 1.1819, 0.743400...   \n",
       "2  [0.7642, 1.6641, 1.0622, 0.5008, 0.4107, 0.133...   \n",
       "3  [0.895, 2.3377, 2.2305, 2.003, 1.9006, 1.0373,...   \n",
       "4  [1.1576, 1.5137, 1.3382, 1.5622, 1.2121, 0.295...   \n",
       "\n",
       "                                         deg_Mg_pH10  \\\n",
       "0  [0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...   \n",
       "1  [0.2504, 1.4021, 0.9804, 0.49670000000000003, ...   \n",
       "2  [0.9559000000000001, 1.9442, 1.0114, 0.5105000...   \n",
       "3  [0.46040000000000003, 3.6695, 0.78550000000000...   \n",
       "4  [1.6912, 5.2652, 2.3901, 0.45890000000000003, ...   \n",
       "\n",
       "                                            deg_pH10  \\\n",
       "0  [2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...   \n",
       "1  [2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...   \n",
       "2  [1.9554, 2.1298, 1.0403, 0.609, 0.5486, 0.386,...   \n",
       "3  [2.7711, 7.365, 1.6924000000000001, 1.43840000...   \n",
       "4  [1.8641, 2.3767, 1.149, 1.0132, 0.9876, 0.0, 0...   \n",
       "\n",
       "                                          deg_Mg_50C  \\\n",
       "0  [0.35810000000000003, 2.9683, 0.2589, 1.4552, ...   \n",
       "1  [0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...   \n",
       "2  [0.22460000000000002, 1.7281, 1.381, 0.6623, 0...   \n",
       "3  [1.073, 2.8604000000000003, 1.9936, 1.0273, 1....   \n",
       "4  [0.49060000000000004, 4.6339, 1.95860000000000...   \n",
       "\n",
       "                                             deg_50C  \n",
       "0  [0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...  \n",
       "1  [0.9501000000000001, 1.7974999999999999, 1.499...  \n",
       "2  [0.5882000000000001, 1.1786, 0.9704, 0.6035, 0...  \n",
       "3  [2.0964, 3.3688000000000002, 0.6399, 2.1053, 1...  \n",
       "4  [1.2852000000000001, 2.5460000000000003, 0.234...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3634, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>structure</th>\n",
       "      <th>predicted_loop_type</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>seq_scored</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>id_00073f8be</td>\n",
       "      <td>GGAAAAGUACGACUUGAGUACGGAAAACGUACCAACUCGAUUAAAA...</td>\n",
       "      <td>......((((((((((.(((((.....))))))))((((((((......</td>\n",
       "      <td>EEEEEESSSSSSSSSSBSSSSSHHHHHSSSSSSSSSSSSSSSSHHH...</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>id_000ae4237</td>\n",
       "      <td>GGAAACGGGUUCCGCGGAUUGCUGCUAAUAAGAGUAAUCUCUAAAU...</td>\n",
       "      <td>.....((((..((((((...(((((.....((((....)))).......</td>\n",
       "      <td>EEEEESSSSIISSSSSSIIISSSSSIIIIISSSSHHHHSSSSIIII...</td>\n",
       "      <td>130</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>id_00131c573</td>\n",
       "      <td>GGAAAACAAAACGGCCUGGAAGACGAAGGAAUUCGGCGCGAAGGCC...</td>\n",
       "      <td>...........((.(((.(.(..((..((..((((...))))..))...</td>\n",
       "      <td>EEEEEEEEEEESSISSSISISIISSIISSIISSSSHHHSSSSIISS...</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>id_00181fd34</td>\n",
       "      <td>GGAAAGGAUCUCUAUCGAAGGAUAGAGAUCGCUCGCGACGGCACGA...</td>\n",
       "      <td>......((((((((((....))))))))))((((((..((.(((.....</td>\n",
       "      <td>EEEEEESSSSSSSSSSHHHHSSSSSSSSSSSSSSSSIISSISSSHH...</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>id_0020473f7</td>\n",
       "      <td>GGAAACCCGCCCGCGCCCGCCCGCGCUGCUGCCGUGCCUCCUCUCC...</td>\n",
       "      <td>.....(((((((((((((((((((((((((((((((((((((((((...</td>\n",
       "      <td>EEEEESSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS...</td>\n",
       "      <td>130</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index            id                                           sequence  \\\n",
       "0      0  id_00073f8be  GGAAAAGUACGACUUGAGUACGGAAAACGUACCAACUCGAUUAAAA...   \n",
       "1      1  id_000ae4237  GGAAACGGGUUCCGCGGAUUGCUGCUAAUAAGAGUAAUCUCUAAAU...   \n",
       "2      2  id_00131c573  GGAAAACAAAACGGCCUGGAAGACGAAGGAAUUCGGCGCGAAGGCC...   \n",
       "3      3  id_00181fd34  GGAAAGGAUCUCUAUCGAAGGAUAGAGAUCGCUCGCGACGGCACGA...   \n",
       "4      4  id_0020473f7  GGAAACCCGCCCGCGCCCGCCCGCGCUGCUGCCGUGCCUCCUCUCC...   \n",
       "\n",
       "                                           structure  \\\n",
       "0  ......((((((((((.(((((.....))))))))((((((((......   \n",
       "1  .....((((..((((((...(((((.....((((....)))).......   \n",
       "2  ...........((.(((.(.(..((..((..((((...))))..))...   \n",
       "3  ......((((((((((....))))))))))((((((..((.(((.....   \n",
       "4  .....(((((((((((((((((((((((((((((((((((((((((...   \n",
       "\n",
       "                                 predicted_loop_type  seq_length  seq_scored  \n",
       "0  EEEEEESSSSSSSSSSBSSSSSHHHHHSSSSSSSSSSSSSSSSHHH...         107          68  \n",
       "1  EEEEESSSSIISSSSSSIIISSSSSIIIIISSSSHHHHSSSSIIII...         130          91  \n",
       "2  EEEEEEEEEEESSISSSISISIISSIISSIISSSSHHHSSSSIISS...         107          68  \n",
       "3  EEEEEESSSSSSSSSSHHHHSSSSSSSSSSSSSSSSIISSISSSHH...         107          68  \n",
       "4  EEEEESSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS...         130          91  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(457953, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_seqpos</th>\n",
       "      <th>reactivity</th>\n",
       "      <th>deg_Mg_pH10</th>\n",
       "      <th>deg_pH10</th>\n",
       "      <th>deg_Mg_50C</th>\n",
       "      <th>deg_50C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00073f8be_0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00073f8be_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00073f8be_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00073f8be_3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_00073f8be_4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_seqpos  reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C  deg_50C\n",
       "0  id_00073f8be_0         0.0          0.0       0.0         0.0      0.0\n",
       "1  id_00073f8be_1         0.0          0.0       0.0         0.0      0.0\n",
       "2  id_00073f8be_2         0.0          0.0       0.0         0.0      0.0\n",
       "3  id_00073f8be_3         0.0          0.0       0.0         0.0      0.0\n",
       "4  id_00073f8be_4         0.0          0.0       0.0         0.0      0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sub.shape)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2096, 107, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = list(sub.columns[1:])\n",
    "print(targets)\n",
    "\n",
    "y_train = []\n",
    "seq_len = train[\"seq_length\"].iloc[0]\n",
    "seq_len_target = train[\"seq_scored\"].iloc[0]\n",
    "ignore = -10000\n",
    "ignore_length = seq_len - seq_len_target\n",
    "for target in targets:\n",
    "    y = np.vstack(train[target])\n",
    "    dummy = np.zeros([y.shape[0], ignore_length]) + ignore\n",
    "    y = np.hstack([y, dummy])\n",
    "    y_train.append(y)\n",
    "y = np.stack(y_train, axis = 2)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "551dafb640464b45a325b55f69d8075c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2096.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(2096, 107, 107, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f5ef71979545d4a677c675844ddaef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=629.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(629, 107, 107, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b648d7c08974e1a8dabd67028e35499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3005.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(3005, 130, 130, 1)\n"
     ]
    }
   ],
   "source": [
    "def get_structure_adj(train):\n",
    "    ## get adjacent matrix from structure sequence\n",
    "    \n",
    "    ## here I calculate adjacent matrix of each base pair, \n",
    "    ## but eventually ignore difference of base pair and integrate into one matrix\n",
    "    Ss = []\n",
    "    for i in tqdm(range(len(train))):\n",
    "        seq_length = train[\"seq_length\"].iloc[i]\n",
    "        structure = train[\"structure\"].iloc[i]\n",
    "        sequence = train[\"sequence\"].iloc[i]\n",
    "\n",
    "        cue = []\n",
    "        a_structures = {\n",
    "            (\"A\", \"U\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"C\", \"G\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"U\", \"G\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"U\", \"A\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"G\", \"C\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"G\", \"U\") : np.zeros([seq_length, seq_length]),\n",
    "        }\n",
    "        a_structure = np.zeros([seq_length, seq_length])\n",
    "        for i in range(seq_length):\n",
    "            if structure[i] == \"(\":\n",
    "                cue.append(i)\n",
    "            elif structure[i] == \")\":\n",
    "                start = cue.pop()\n",
    "#                 a_structure[start, i] = 1\n",
    "#                 a_structure[i, start] = 1\n",
    "                a_structures[(sequence[start], sequence[i])][start, i] = 1\n",
    "                a_structures[(sequence[i], sequence[start])][i, start] = 1\n",
    "        \n",
    "        a_strc = np.stack([a for a in a_structures.values()], axis = 2)\n",
    "        a_strc = np.sum(a_strc, axis = 2, keepdims = True)\n",
    "        Ss.append(a_strc)\n",
    "    \n",
    "    Ss = np.array(Ss)\n",
    "    print(Ss.shape)\n",
    "    return Ss\n",
    "Ss = get_structure_adj(train)\n",
    "Ss_pub = get_structure_adj(test_pub)\n",
    "Ss_pri = get_structure_adj(test_pri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2096, 107, 107, 3)\n",
      "(629, 107, 107, 3)\n",
      "(3005, 130, 130, 3)\n"
     ]
    }
   ],
   "source": [
    "def get_distance_matrix(As):\n",
    "    ## adjacent matrix based on distance on the sequence\n",
    "    ## D[i, j] = 1 / (abs(i - j) + 1) ** pow, pow = 1, 2, 4\n",
    "    \n",
    "    idx = np.arange(As.shape[1])\n",
    "    Ds = []\n",
    "    for i in range(len(idx)):\n",
    "        d = np.abs(idx[i] - idx)\n",
    "        Ds.append(d)\n",
    "\n",
    "    Ds = np.array(Ds) + 1\n",
    "    Ds = 1/Ds\n",
    "    Ds = Ds[None, :,:]\n",
    "    Ds = np.repeat(Ds, len(As), axis = 0)\n",
    "    \n",
    "    Dss = []\n",
    "    for i in [1, 2, 4]: \n",
    "        Dss.append(Ds ** i)\n",
    "    Ds = np.stack(Dss, axis = 3)\n",
    "    print(Ds.shape)\n",
    "    return Ds\n",
    "\n",
    "Ds = get_distance_matrix(As)\n",
    "Ds_pub = get_distance_matrix(As_pub)\n",
    "Ds_pri = get_distance_matrix(As_pri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2096, 107, 107, 5), (629, 107, 107, 5), (3005, 130, 130, 5))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## concat adjecent\n",
    "As = np.concatenate([As[:,:,:,None], Ss, Ds], axis = 3).astype(np.float32)\n",
    "As_pub = np.concatenate([As_pub[:,:,:,None], Ss_pub, Ds_pub], axis = 3).astype(np.float32)\n",
    "As_pri = np.concatenate([As_pri[:,:,:,None], Ss_pri, Ds_pri], axis = 3).astype(np.float32)\n",
    "del Ss, Ds, Ss_pub, Ds_pub, Ss_pri, Ds_pri\n",
    "As.shape, As_pub.shape, As_pri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 18, 20, 24, 33, 34, 36, 40, 65, 66, 68, 72, 129, 130, 132, 136, 257, 258, 260, 264, 513, 514, 516, 520, 1025, 1026, 1028, 1032]\n",
      "(2096, 107, 39)\n",
      "[17, 18, 20, 24, 33, 34, 36, 40, 65, 66, 68, 72, 129, 130, 132, 136, 257, 258, 260, 264, 513, 514, 516, 520, 1025, 1026, 1028, 1032]\n",
      "(629, 107, 39)\n",
      "[17, 18, 20, 24, 33, 34, 36, 40, 65, 66, 68, 72, 129, 130, 132, 136, 257, 258, 260, 264, 513, 514, 516, 520, 1025, 1026, 1028, 1032]\n",
      "(3005, 130, 39)\n"
     ]
    }
   ],
   "source": [
    "## sequence\n",
    "def return_ohe(n, i):\n",
    "    tmp = [0] * n\n",
    "    tmp[i] = 1\n",
    "    return tmp\n",
    "\n",
    "def get_input(train):\n",
    "    ## get node features, which is one hot encoded\n",
    "    mapping = {}\n",
    "    vocab = [\"A\", \"G\", \"C\", \"U\"]\n",
    "    for i, s in enumerate(vocab):\n",
    "        mapping[s] = return_ohe(len(vocab), i)\n",
    "    X_node = np.stack(train[\"sequence\"].apply(lambda x : list(map(lambda y : mapping[y], list(x)))))\n",
    "\n",
    "    mapping = {}\n",
    "    vocab = [\"S\", \"M\", \"I\", \"B\", \"H\", \"E\", \"X\"]\n",
    "    for i, s in enumerate(vocab):\n",
    "        mapping[s] = return_ohe(len(vocab), i)\n",
    "    X_loop = np.stack(train[\"predicted_loop_type\"].apply(lambda x : list(map(lambda y : mapping[y], list(x)))))\n",
    "    \n",
    "    mapping = {}\n",
    "    vocab = [\".\", \"(\", \")\"]\n",
    "    for i, s in enumerate(vocab):\n",
    "        mapping[s] = return_ohe(len(vocab), i)\n",
    "    X_structure = np.stack(train[\"structure\"].apply(lambda x : list(map(lambda y : mapping[y], list(x)))))\n",
    "    \n",
    "    \n",
    "    X_node = np.concatenate([X_node, X_loop], axis = 2)\n",
    "    \n",
    "    ## interaction\n",
    "    a = np.sum(X_node * (2 ** np.arange(X_node.shape[2])[None, None, :]), axis = 2)\n",
    "    vocab = sorted(set(a.flatten()))\n",
    "    print(vocab)\n",
    "    ohes = []\n",
    "    for v in vocab:\n",
    "        ohes.append(a == v)\n",
    "    ohes = np.stack(ohes, axis = 2)\n",
    "    X_node = np.concatenate([X_node, ohes], axis = 2).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    print(X_node.shape)\n",
    "    return X_node\n",
    "\n",
    "X_node = get_input(train)\n",
    "X_node_pub = get_input(test_pub)\n",
    "X_node_pri = get_input(test_pri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as L\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def mcrmse(t, p, seq_len_target = seq_len_target):\n",
    "    ## calculate mcrmse score by using numpy\n",
    "    t = t[:, :seq_len_target]\n",
    "    p = p[:, :seq_len_target]\n",
    "    \n",
    "    score = np.mean(np.sqrt(np.mean(np.mean((p - t) ** 2, axis = 1), axis = 0)))\n",
    "    return score\n",
    "\n",
    "def mcrmse_loss(t, y, seq_len_target = seq_len_target):\n",
    "    ## calculate mcrmse score by using tf\n",
    "    t = t[:, :seq_len_target]\n",
    "    y = y[:, :seq_len_target]\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.sqrt(tf.reduce_mean(tf.reduce_mean((t - y) ** 2, axis = 1), axis = 0)))\n",
    "    return loss\n",
    "\n",
    "def attention(x_inner, x_outer, n_factor, dropout):\n",
    "    x_Q =  L.Conv1D(n_factor, 1, activation='linear', \n",
    "                  kernel_initializer='glorot_uniform',\n",
    "                  bias_initializer='glorot_uniform',\n",
    "                 )(x_inner)\n",
    "    x_K =  L.Conv1D(n_factor, 1, activation='linear', \n",
    "                  kernel_initializer='glorot_uniform',\n",
    "                  bias_initializer='glorot_uniform',\n",
    "                 )(x_outer)\n",
    "    x_V =  L.Conv1D(n_factor, 1, activation='linear', \n",
    "                  kernel_initializer='glorot_uniform',\n",
    "                  bias_initializer='glorot_uniform',\n",
    "                 )(x_outer)\n",
    "    x_KT = L.Permute((2, 1))(x_K)\n",
    "    res = L.Lambda(lambda c: K.batch_dot(c[0], c[1]) / np.sqrt(n_factor))([x_Q, x_KT])\n",
    "#     res = tf.expand_dims(res, axis = 3)\n",
    "#     res = L.Conv2D(16, 3, 1, padding = \"same\", activation = \"relu\")(res)\n",
    "#     res = L.Conv2D(1, 3, 1, padding = \"same\", activation = \"relu\")(res)\n",
    "#     res = tf.squeeze(res, axis = 3)\n",
    "    att = L.Lambda(lambda c: K.softmax(c, axis=-1))(res)\n",
    "    att = L.Lambda(lambda c: K.batch_dot(c[0], c[1]))([att, x_V])\n",
    "    return att\n",
    "\n",
    "def multi_head_attention(x, y, n_factor, n_head, dropout):\n",
    "    if n_head == 1:\n",
    "        att = attention(x, y, n_factor, dropout)\n",
    "    else:\n",
    "        n_factor_head = n_factor // n_head\n",
    "        heads = [attention(x, y, n_factor_head, dropout) for i in range(n_head)]\n",
    "        att = L.Concatenate()(heads)\n",
    "        att = L.Dense(n_factor, \n",
    "                      kernel_initializer='glorot_uniform',\n",
    "                      bias_initializer='glorot_uniform',\n",
    "                     )(att)\n",
    "    x = L.Add()([x, att])\n",
    "    x = L.LayerNormalization()(x)\n",
    "    if dropout > 0:\n",
    "        x = L.Dropout(dropout)(x)\n",
    "    return x\n",
    "\n",
    "def res(x, unit, kernel = 3, rate = 0.1):\n",
    "    h = L.Conv1D(unit, kernel, 1, padding = \"same\", activation = None)(x)\n",
    "    h = L.LayerNormalization()(h)\n",
    "    h = L.LeakyReLU()(h)\n",
    "    h = L.Dropout(rate)(h)\n",
    "    return L.Add()([x, h])\n",
    "\n",
    "def forward(x, unit, kernel = 3, rate = 0.1):\n",
    "#     h = L.Dense(unit, None)(x)\n",
    "    h = L.Conv1D(unit, kernel, 1, padding = \"same\", activation = None)(x)\n",
    "    h = L.LayerNormalization()(h)\n",
    "    h = L.Dropout(rate)(h)\n",
    "#         h = tf.keras.activations.swish(h)\n",
    "    h = L.LeakyReLU()(h)\n",
    "    h = res(h, unit, kernel, rate)\n",
    "    return h\n",
    "\n",
    "def adj_attn(x, adj, unit, n = 2, rate = 0.1):\n",
    "    x_a = x\n",
    "    x_as = []\n",
    "    for i in range(n):\n",
    "        x_a = forward(x_a, unit)\n",
    "        x_a = tf.matmul(adj, x_a) ## aggregate neighborhoods\n",
    "        x_as.append(x_a)\n",
    "    if n == 1:\n",
    "        x_a = x_as[0]\n",
    "    else:\n",
    "        x_a = L.Concatenate()(x_as)\n",
    "    x_a = forward(x_a, unit)\n",
    "    return x_a\n",
    "\n",
    "\n",
    "def get_base(config):\n",
    "    ## base model architecture \n",
    "    ## node, adj -> middle feature\n",
    "    \n",
    "    node = tf.keras.Input(shape = (None, X_node.shape[2]), name = \"node\")\n",
    "    adj = tf.keras.Input(shape = (None, None, As.shape[3]), name = \"adj\")\n",
    "    \n",
    "    adj_learned = L.Dense(1, \"relu\")(adj)\n",
    "    adj_all = L.Concatenate(axis = 3)([adj, adj_learned])\n",
    "        \n",
    "    xs = []\n",
    "    xs.append(node)\n",
    "    x1 = forward(node, 128, kernel = 3, rate = 0.0)\n",
    "    x2 = forward(x1, 64, kernel = 6, rate = 0.0)\n",
    "    x3 = forward(x2, 32, kernel = 15, rate = 0.0)\n",
    "    x4 = forward(x3, 16, kernel = 30, rate = 0.0)\n",
    "    x = L.Concatenate()([x1, x2, x3, x4])\n",
    "    \n",
    "    for unit in [64, 32]:\n",
    "        x_as = []\n",
    "        for i in range(adj_all.shape[3]):\n",
    "            x_a = adj_attn(x, adj_all[:, :, :, i], unit, rate = 0.0)\n",
    "            x_as.append(x_a)\n",
    "        x_c = forward(x, unit, kernel = 30)\n",
    "        \n",
    "        x = L.Concatenate()(x_as + [x_c])\n",
    "        x = forward(x, unit)\n",
    "        x = multi_head_attention(x, x, unit, 4, 0.0)\n",
    "        xs.append(x)\n",
    "        \n",
    "    x = L.Concatenate()(xs)\n",
    "\n",
    "    model = tf.keras.Model(inputs = [node, adj], outputs = [x])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_ae_model(base, config):\n",
    "    ## denoising auto encoder part\n",
    "    ## node, adj -> middle feature -> node\n",
    "    \n",
    "    node = tf.keras.Input(shape = (None, X_node.shape[2]), name = \"node\")\n",
    "    adj = tf.keras.Input(shape = (None, None, As.shape[3]), name = \"adj\")\n",
    "\n",
    "    x = base([L.SpatialDropout1D(0.3)(node), adj])\n",
    "    x = forward(x, 64, rate = 0.3)\n",
    "    p = L.Dense(X_node.shape[2], \"sigmoid\")(x)\n",
    "    \n",
    "    loss = - tf.reduce_mean(20 * node * tf.math.log(p + 1e-4) + (1 - node) * tf.math.log(1 - p + 1e-4))\n",
    "    model = tf.keras.Model(inputs = [node, adj], outputs = [loss])\n",
    "    \n",
    "    opt = get_optimizer()\n",
    "    model.compile(optimizer = opt, loss = lambda t, y : y)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model(base, config):\n",
    "    ## regression part\n",
    "    ## node, adj -> middle feature -> prediction of targets\n",
    "    \n",
    "    node = tf.keras.Input(shape = (None, X_node.shape[2]), name = \"node\")\n",
    "    adj = tf.keras.Input(shape = (None, None, As.shape[3]), name = \"adj\")\n",
    "    \n",
    "    x = base([node, adj])\n",
    "    x = forward(x, 128, rate = 0.4)\n",
    "    x = L.Dense(5, None)(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs = [node, adj], outputs = [x])\n",
    "    \n",
    "    opt = get_optimizer()\n",
    "    model.compile(optimizer = opt, loss = mcrmse_loss)\n",
    "    return model\n",
    "\n",
    "def get_optimizer():\n",
    "    sgd = tf.keras.optimizers.SGD(0.05, momentum = 0.9, nesterov=True)\n",
    "    adam = tf.optimizers.Adam()\n",
    "    radam = tfa.optimizers.RectifiedAdam()\n",
    "    lookahead = tfa.optimizers.Lookahead(adam, sync_period=6)\n",
    "    swa = tfa.optimizers.SWA(adam)\n",
    "    return adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 0 ------\n",
      "--- train ---\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 186s 3s/step - loss: 0.8798\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 323s 5s/step - loss: 0.3110\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 300s 5s/step - loss: 0.1667\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 900s 14s/step - loss: 0.1119\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 133s 2s/step - loss: 0.0862\n",
      "--- public ---\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 39s 2s/step - loss: 0.0714\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 38s 2s/step - loss: 0.0677\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0610\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 39s 2s/step - loss: 0.0589\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 38s 2s/step - loss: 0.0579\n",
      "--- private ---\n",
      "Epoch 1/5\n",
      "94/94 [==============================] - 278s 3s/step - loss: 0.0562\n",
      "Epoch 2/5\n",
      "94/94 [==============================] - 288s 3s/step - loss: 0.0476\n",
      "Epoch 3/5\n",
      "94/94 [==============================] - 267s 3s/step - loss: 0.0411\n",
      "Epoch 4/5\n",
      "94/94 [==============================] - 254s 3s/step - loss: 0.0369\n",
      "Epoch 5/5\n",
      "94/94 [==============================] - 256s 3s/step - loss: 0.0330\n",
      "------ 1 ------\n",
      "--- train ---\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 154s 2s/step - loss: 0.0259\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 149s 2s/step - loss: 0.0227\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 145s 2s/step - loss: 0.0211\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 143s 2s/step - loss: 0.0246\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 143s 2s/step - loss: 0.0187\n",
      "--- public ---\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0186\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.0183\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0163\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0162\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0151\n",
      "--- private ---\n",
      "Epoch 1/5\n",
      "94/94 [==============================] - 258s 3s/step - loss: 0.0191\n",
      "Epoch 2/5\n",
      "94/94 [==============================] - 260s 3s/step - loss: 0.0173\n",
      "Epoch 3/5\n",
      "94/94 [==============================] - 255s 3s/step - loss: 0.0182\n",
      "Epoch 4/5\n",
      "94/94 [==============================] - 256s 3s/step - loss: 0.0176\n",
      "Epoch 5/5\n",
      "94/94 [==============================] - 257s 3s/step - loss: 0.0176\n",
      "------ 2 ------\n",
      "--- train ---\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 144s 2s/step - loss: 0.0141\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 141s 2s/step - loss: 0.0121\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 148s 2s/step - loss: 0.0118\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 139s 2s/step - loss: 0.0115\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 140s 2s/step - loss: 0.0119\n",
      "--- public ---\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.0129\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.0125\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0140\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0110\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0123\n",
      "--- private ---\n",
      "Epoch 1/5\n",
      "94/94 [==============================] - 260s 3s/step - loss: 0.0134\n",
      "Epoch 2/5\n",
      "94/94 [==============================] - 250s 3s/step - loss: 0.0118\n",
      "Epoch 3/5\n",
      "94/94 [==============================] - 251s 3s/step - loss: 0.0116\n",
      "Epoch 4/5\n",
      "94/94 [==============================] - 261s 3s/step - loss: 0.0146\n",
      "Epoch 5/5\n",
      "94/94 [==============================] - 270s 3s/step - loss: 0.0131\n",
      "------ 3 ------\n",
      "--- train ---\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 160s 2s/step - loss: 0.0100\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 181s 3s/step - loss: 0.0090\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 174s 3s/step - loss: 0.0084\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 203s 3s/step - loss: 0.0076\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 177s 3s/step - loss: 0.0082\n",
      "--- public ---\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 59s 3s/step - loss: 0.0097\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 51s 3s/step - loss: 0.0071\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 51s 3s/step - loss: 0.0079\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 50s 2s/step - loss: 0.0131\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 49s 2s/step - loss: 0.0107\n",
      "--- private ---\n",
      "Epoch 1/5\n",
      "94/94 [==============================] - 302s 3s/step - loss: 0.0120\n",
      "Epoch 2/5\n",
      "94/94 [==============================] - 256s 3s/step - loss: 0.0090\n",
      "Epoch 3/5\n",
      "94/94 [==============================] - 702s 7s/step - loss: 0.0094\n",
      "Epoch 4/5\n",
      "94/94 [==============================] - 339s 4s/step - loss: 0.0087\n",
      "Epoch 5/5\n",
      "94/94 [==============================] - 328s 3s/step - loss: 0.0080\n",
      "****** save ae model ******\n"
     ]
    }
   ],
   "source": [
    "## here train denoising auto encoder model using all data\n",
    "\n",
    "config = {} ## not use now\n",
    "if ae_epochs > 0:\n",
    "    base = get_base(config)\n",
    "    ae_model = get_ae_model(base, config)\n",
    "    ## TODO : simultaneous train\n",
    "    for i in range(ae_epochs//ae_epochs_each):\n",
    "        print(f\"------ {i} ------\")\n",
    "        print(\"--- train ---\")\n",
    "        ae_model.fit([X_node, As], [X_node[:,0]],\n",
    "                  epochs = ae_epochs_each,\n",
    "                  batch_size = ae_batch_size)\n",
    "        print(\"--- public ---\")\n",
    "        ae_model.fit([X_node_pub, As_pub], [X_node_pub[:,0]],\n",
    "                  epochs = ae_epochs_each,\n",
    "                  batch_size = ae_batch_size)\n",
    "        print(\"--- private ---\")\n",
    "        ae_model.fit([X_node_pri, As_pri], [X_node_pri[:,0]],\n",
    "                  epochs = ae_epochs_each,\n",
    "                  batch_size = ae_batch_size)\n",
    "        gc.collect()\n",
    "    print(\"****** save ae model ******\")\n",
    "    base.save_weights(\"./base_ae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ fold 0 start -----\n",
      "------ fold 0 start -----\n",
      "------ fold 0 start -----\n",
      "****** load ae model ******\n",
      "epochs : 30, batch_size : 8\n",
      "Epoch 1/30\n",
      "210/210 [==============================] - 164s 783ms/step - loss: 0.5340\n",
      "Epoch 2/30\n",
      "210/210 [==============================] - 147s 699ms/step - loss: 0.3279\n",
      "Epoch 3/30\n",
      "210/210 [==============================] - 161s 767ms/step - loss: 0.3021 - val_loss: 0.2789\n",
      "Epoch 4/30\n",
      "210/210 [==============================] - 135s 643ms/step - loss: 0.2855\n",
      "Epoch 5/30\n",
      "210/210 [==============================] - 133s 633ms/step - loss: 0.2761\n",
      "Epoch 6/30\n",
      "210/210 [==============================] - 142s 675ms/step - loss: 0.2696 - val_loss: 0.2675\n",
      "Epoch 7/30\n",
      "210/210 [==============================] - 35864s 171s/step - loss: 0.2638\n",
      "Epoch 8/30\n",
      "210/210 [==============================] - 11640s 55s/step - loss: 0.2584\n",
      "Epoch 9/30\n",
      "210/210 [==============================] - 153s 727ms/step - loss: 0.2550 - val_loss: 0.2562\n",
      "Epoch 10/30\n",
      "210/210 [==============================] - 135s 642ms/step - loss: 0.2515\n",
      "Epoch 11/30\n",
      "210/210 [==============================] - 133s 632ms/step - loss: 0.2461\n",
      "Epoch 12/30\n",
      "210/210 [==============================] - 141s 673ms/step - loss: 0.2431 - val_loss: 0.2499\n",
      "Epoch 13/30\n",
      "210/210 [==============================] - 4549s 22s/step - loss: 0.2400\n",
      "Epoch 14/30\n",
      "210/210 [==============================] - 149s 711ms/step - loss: 0.2373\n",
      "Epoch 15/30\n",
      "210/210 [==============================] - 176s 837ms/step - loss: 0.2346 - val_loss: 0.2453\n",
      "Epoch 16/30\n",
      "210/210 [==============================] - 138s 655ms/step - loss: 0.2324\n",
      "Epoch 17/30\n",
      "210/210 [==============================] - 137s 652ms/step - loss: 0.2283\n",
      "Epoch 18/30\n",
      "210/210 [==============================] - 144s 686ms/step - loss: 0.2276 - val_loss: 0.2444\n",
      "Epoch 19/30\n",
      "210/210 [==============================] - 147s 699ms/step - loss: 0.2265\n",
      "Epoch 20/30\n",
      "210/210 [==============================] - 154s 735ms/step - loss: 0.2230\n",
      "Epoch 21/30\n",
      "210/210 [==============================] - 156s 741ms/step - loss: 0.2215 - val_loss: 0.2369\n",
      "Epoch 22/30\n",
      "210/210 [==============================] - 139s 662ms/step - loss: 0.2193\n",
      "Epoch 23/30\n",
      "210/210 [==============================] - 144s 687ms/step - loss: 0.2173\n",
      "Epoch 24/30\n",
      "210/210 [==============================] - 148s 704ms/step - loss: 0.2156 - val_loss: 0.2342\n",
      "Epoch 25/30\n",
      "210/210 [==============================] - 144s 686ms/step - loss: 0.2133\n",
      "Epoch 26/30\n",
      "210/210 [==============================] - 138s 657ms/step - loss: 0.2108\n",
      "Epoch 27/30\n",
      "210/210 [==============================] - 147s 700ms/step - loss: 0.2097 - val_loss: 0.2341\n",
      "Epoch 28/30\n",
      "210/210 [==============================] - 139s 660ms/step - loss: 0.2089\n",
      "Epoch 29/30\n",
      "210/210 [==============================] - 140s 665ms/step - loss: 0.2080\n",
      "Epoch 30/30\n",
      "210/210 [==============================] - 146s 694ms/step - loss: 0.2068 - val_loss: 0.2346\n",
      "epochs : 10, batch_size : 16\n",
      "Epoch 1/10\n",
      "105/105 [==============================] - 123s 1s/step - loss: 0.2020\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 124s 1s/step - loss: 0.1981\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 131s 1s/step - loss: 0.1968 - val_loss: 0.2309\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 123s 1s/step - loss: 0.1959\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 123s 1s/step - loss: 0.1953\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 130s 1s/step - loss: 0.1943 - val_loss: 0.2312\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 122s 1s/step - loss: 0.1942\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 124s 1s/step - loss: 0.1932\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - 132s 1s/step - loss: 0.1934 - val_loss: 0.2304\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - 123s 1s/step - loss: 0.1921\n",
      "epochs : 3, batch_size : 32\n",
      "Epoch 1/3\n",
      "53/53 [==============================] - 120s 2s/step - loss: 0.1897\n",
      "Epoch 2/3\n",
      "53/53 [==============================] - 122s 2s/step - loss: 0.1869\n",
      "Epoch 3/3\n",
      "53/53 [==============================] - 128s 2s/step - loss: 0.1863 - val_loss: 0.2311\n",
      "epochs : 3, batch_size : 64\n",
      "Epoch 1/3\n",
      "27/27 [==============================] - 113s 4s/step - loss: 0.1847\n",
      "Epoch 2/3\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.1835\n",
      "Epoch 3/3\n",
      "27/27 [==============================] - 8964s 332s/step - loss: 0.1829 - val_loss: 0.2308\n",
      "epochs : 5, batch_size : 128\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 183694s 13121s/step - loss: 0.1825\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 147s 10s/step - loss: 0.1817\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 161s 12s/step - loss: 0.1813 - val_loss: 0.2302\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 160s 11s/step - loss: 0.1813\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 164s 12s/step - loss: 0.1813\n",
      "epochs : 5, batch_size : 256\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 176s 25s/step - loss: 0.1805\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 192s 27s/step - loss: 0.1803\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 190s 27s/step - loss: 0.1802 - val_loss: 0.2297\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 239867s 34267s/step - loss: 0.1796\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 156s 22s/step - loss: 0.1794\n",
      "fold 0: mcrmse 0.22993461050308994\n",
      "------ fold 1 start -----\n",
      "------ fold 1 start -----\n",
      "------ fold 1 start -----\n",
      "****** load ae model ******\n",
      "epochs : 30, batch_size : 8\n",
      "Epoch 1/30\n",
      "210/210 [==============================] - 197s 939ms/step - loss: 0.5305\n",
      "Epoch 2/30\n",
      "210/210 [==============================] - 196s 934ms/step - loss: 0.3279\n",
      "Epoch 3/30\n",
      "210/210 [==============================] - 192s 913ms/step - loss: 0.3021 - val_loss: 0.2819\n",
      "Epoch 4/30\n",
      "210/210 [==============================] - 190s 905ms/step - loss: 0.2895\n",
      "Epoch 5/30\n",
      " 36/210 [====>.........................] - ETA: 2:10 - loss: 0.2842"
     ]
    }
   ],
   "source": [
    "## here train regression model from pretrain auto encoder model\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(5, shuffle = True, random_state = 42)\n",
    "\n",
    "scores = []\n",
    "preds = np.zeros([len(X_node), X_node.shape[1], 5])\n",
    "for i, (tr_idx, va_idx) in enumerate(kfold.split(X_node, As)):\n",
    "    print(f\"------ fold {i} start -----\")\n",
    "    print(f\"------ fold {i} start -----\")\n",
    "    print(f\"------ fold {i} start -----\")\n",
    "    X_node_tr = X_node[tr_idx]\n",
    "    X_node_va = X_node[va_idx]\n",
    "    As_tr = As[tr_idx]\n",
    "    As_va = As[va_idx]\n",
    "    y_tr = y[tr_idx]\n",
    "    y_va = y[va_idx]\n",
    "    \n",
    "    base = get_base(config)\n",
    "    if ae_epochs > 0:\n",
    "        print(\"****** load ae model ******\")\n",
    "        base.load_weights(\"./base_ae\")\n",
    "    model = get_model(base, config)\n",
    "    if pretrain_dir is not None:\n",
    "        d = f\"./model{i}\"\n",
    "        print(f\"--- load from {d} ---\")\n",
    "        model.load_weights(d)\n",
    "    for epochs, batch_size in zip(epochs_list, batch_size_list):\n",
    "        print(f\"epochs : {epochs}, batch_size : {batch_size}\")\n",
    "        model.fit([X_node_tr, As_tr], [y_tr],\n",
    "                  validation_data=([X_node_va, As_va], [y_va]),\n",
    "                  epochs = epochs,\n",
    "                  batch_size = batch_size, validation_freq = 3)\n",
    "        \n",
    "    model.save_weights(f\"./model{i}\")\n",
    "    p = model.predict([X_node_va, As_va])\n",
    "    scores.append(mcrmse(y_va, p))\n",
    "    print(f\"fold {i}: mcrmse {scores[-1]}\")\n",
    "    preds[va_idx] = p\n",
    "    if one_fold:\n",
    "        break\n",
    "        \n",
    "pd.to_pickle(preds, \"oof.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pub = 0\n",
    "p_pri = 0\n",
    "for i in range(5):\n",
    "    model.load_weights(f\"./model{i}\")\n",
    "    p_pub += model.predict([X_node_pub, As_pub]) / 5\n",
    "    p_pri += model.predict([X_node_pri, As_pri]) / 5\n",
    "    if one_fold:\n",
    "        p_pub *= 5\n",
    "        p_pri *= 5\n",
    "        break\n",
    "\n",
    "for i, target in enumerate(targets):\n",
    "    test_pub[target] = [list(p_pub[k, :, i]) for k in range(p_pub.shape[0])]\n",
    "    test_pri[target] = [list(p_pri[k, :, i]) for k in range(p_pri.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ls = []\n",
    "for df, preds in [(test_pub, p_pub), (test_pri, p_pri)]:\n",
    "    for i, uid in enumerate(df.id):\n",
    "        single_pred = preds[i]\n",
    "\n",
    "        single_df = pd.DataFrame(single_pred, columns=targets)\n",
    "        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "\n",
    "        preds_ls.append(single_df)\n",
    "\n",
    "preds_df = pd.concat(preds_ls)\n",
    "preds_df.to_csv(\"submission.csv\", index = False)\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
