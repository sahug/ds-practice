{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic - Machine Learning from Disaster - Accuracy Score - 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/Titanic - Machine Learning from Disaster/train.csv\")\n",
    "test_df = pd.read_csv(\"data/Titanic - Machine Learning from Disaster/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"__Train_DataSet_\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"__Test_DataSet_\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missingdata(data):\n",
    "    total = data.isnull().sum().sort_values(ascending=False)\n",
    "    percent = (data.isnull().sum() / data.isnull().count() * 100).sort_values(\n",
    "        ascending=False\n",
    "    )\n",
    "    ms = pd.concat([total, percent], axis=1, keys=[\"Total\", \"Percent\"])\n",
    "    ms = ms[ms[\"Percent\"] > 0]\n",
    "    f, ax = plt.subplots(figsize=(8, 6))\n",
    "    plt.xticks(rotation=\"90\")\n",
    "    fig = sns.barplot(ms.index, ms[\"Percent\"], color=\"green\", alpha=0.8)\n",
    "    plt.xlabel(\"Features\", fontsize=15)\n",
    "    plt.ylabel(\"Percent of missing values\", fontsize=15)\n",
    "    plt.title(\"Percent missing data by feature\", fontsize=15)\n",
    "    return ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingdata(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingdata(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"Age\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Embarked\"].fillna(train_df[\"Embarked\"].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"Fare\"].fillna(test_df[\"Fare\"].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cabin Featueres has more than 75% of missing data in both Test and train data so we are remove the Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_column = [\"Cabin\"]\n",
    "train_df.drop(drop_column, axis=1, inplace=True)\n",
    "test_df.drop(drop_column, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the test and train Age features contains more the 15% of missing Data so we are fill with the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"Age\"].fillna(test_df[\"Age\"].median(), inplace=True)\n",
    "train_df[\"Age\"].fillna(train_df[\"Age\"].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"check the nan value in train data\")\n",
    "print(train_df.isnull().sum())\n",
    "print(\"___\" * 30)\n",
    "print(\"check the nan value in test data\")\n",
    "print(test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combine test and train as single to apply some function\n",
    "all_data = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new feature FamilySize as a combination of SibSp and Parch\n",
    "for dataset in all_data:\n",
    "    dataset[\"FamilySize\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "# Define function to extract titles from passenger names\n",
    "def get_title(name):\n",
    "    title_search = re.search(\" ([A-Za-z]+)\\.\", name)\n",
    "\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "# Create a new feature Title, containing the titles of passenger names\n",
    "for dataset in all_data:\n",
    "    dataset[\"Title\"] = dataset[\"Name\"].apply(get_title)\n",
    "\n",
    "# Group all non-common titles into one single grouping \"Rare\"\n",
    "for dataset in all_data:\n",
    "    dataset[\"Title\"] = dataset[\"Title\"].replace(\n",
    "        [\n",
    "            \"Lady\",\n",
    "            \"Countess\",\n",
    "            \"Capt\",\n",
    "            \"Col\",\n",
    "            \"Don\",\n",
    "            \"Dr\",\n",
    "            \"Major\",\n",
    "            \"Rev\",\n",
    "            \"Sir\",\n",
    "            \"Jonkheer\",\n",
    "            \"Dona\",\n",
    "        ],\n",
    "        \"Rare\",\n",
    "    )\n",
    "\n",
    "    dataset[\"Title\"] = dataset[\"Title\"].replace(\"Mlle\", \"Miss\")\n",
    "    dataset[\"Title\"] = dataset[\"Title\"].replace(\"Ms\", \"Miss\")\n",
    "    dataset[\"Title\"] = dataset[\"Title\"].replace(\"Mme\", \"Mrs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create bin for age features\n",
    "for dataset in all_data:\n",
    "    dataset[\"Age_bin\"] = pd.cut(\n",
    "        dataset[\"Age\"],\n",
    "        bins=[0, 12, 20, 40, 120],\n",
    "        labels=[\"Children\", \"Teenage\", \"Adult\", \"Elder\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create bin for fare features\n",
    "for dataset in all_data:\n",
    "    dataset[\"Fare_bin\"] = pd.cut(\n",
    "        dataset[\"Fare\"],\n",
    "        bins=[0, 7.91, 14.45, 31, 120],\n",
    "        labels=[\"Low_fare\", \"median_fare\", \"Average_fare\", \"high_fare\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for our reference making a copy of both DataSet start working for copy of dataset\n",
    "traindf = train_df\n",
    "testdf = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dat = [traindf, testdf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in all_dat:\n",
    "    drop_column = [\"Age\", \"Fare\", \"Name\", \"Ticket\"]\n",
    "    dataset.drop(drop_column, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_column = [\"PassengerId\"]\n",
    "traindf.drop(drop_column, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now every thing almost ready only one step we converted the catergical features in numerical by using dummy variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.get_dummies(\n",
    "    traindf,\n",
    "    columns=[\"Sex\", \"Title\", \"Age_bin\", \"Embarked\", \"Fare_bin\"],\n",
    "    prefix=[\"Sex\", \"Title\", \"Age_type\", \"Em_type\", \"Fare_type\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.get_dummies(\n",
    "    testdf,\n",
    "    columns=[\"Sex\", \"Title\", \"Age_bin\", \"Embarked\", \"Fare_bin\"],\n",
    "    prefix=[\"Sex\", \"Title\", \"Age_type\", \"Em_type\", \"Fare_type\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Between The Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(\n",
    "    traindf.corr(), annot=True, cmap=\"RdYlGn\", linewidths=0.2\n",
    ")  # data.corr()-->correlation matrix\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(20, 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting The Heatmap The first thing to note is that only the numeric features are compared as it is obvious that we cannot correlate between alphabets or strings. Before understanding the plot, let us see what exactly correlation is.\n",
    "\n",
    "`POSITIVE CORRELATION`: If an increase in feature A leads to increase in feature B, then they are positively correlated. A value 1 means perfect positive correlation.\n",
    "\n",
    "`NEGATIVE CORRELATION`: If an increase in feature A leads to decrease in feature B, then they are negatively correlated. A value -1 means perfect negative correlation.\n",
    "\n",
    "Now lets say that two features are highly or perfectly correlated, so the increase in one leads to increase in the other. This means that both the features are containing highly similar information and there is very little or no variance in information. This is known as MultiColinearity as both of them contains almost the same information.\n",
    "\n",
    "So do you think we should use both of them as one of them is redundant. While making or training models, we should try to eliminate redundant features as it reduces training time and many such advantages.\n",
    "\n",
    "Now from the above heatmap,we can see that the features are not much correlated. The highest correlation is between SibSp and Parch i.e 0.41. So we can carry on with all features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairplots\n",
    "Finally let us generate some pairplots to observe the distribution of data from one feature to the other. Once again we use Seaborn to help us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(\n",
    "    data=train_df,\n",
    "    hue=\"Survived\",\n",
    "    palette=\"seismic\",\n",
    "    size=1.2,\n",
    "    diag_kind=\"kde\",\n",
    "    diag_kws=dict(shade=True),\n",
    "    plot_kws=dict(s=10),\n",
    ")\n",
    "g.set(xticklabels=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "Now we are ready to train a model and predict the required solution. There are lot of predictive modelling algorithms to choose from. We must understand the type of problem and solution requirement to narrow down to a select few models which we can evaluate. Our problem is a classification and regression problem. We want to identify relationship between output (Survived or not) with other variables or features (Gender, Age, Port...). We are also perfoming a category of machine learning which is called supervised learning as we are training our model with a given dataset. With these two criteria - Supervised Learning plus Classification and Regression, we can narrow down our choice of models to a few. These include:\n",
    "\n",
    " - Logistic Regression\n",
    " - KNN\n",
    " - Support Vector Machines\n",
    " - Naive Bayes classifier\n",
    " - Decision Tree\n",
    " - Random Forrest\n",
    " - Linear Discriminant Analysis\n",
    " - Ada Boost Classifier\n",
    " - Gradient Boosting Classifier\n",
    "\n",
    "And also compared above given classifiers and evaluate the mean accuracy of each of them by a stratified kfold cross validation procedure and plot accuracy based confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score  # for accuracy_score\n",
    "from sklearn.metrics import confusion_matrix  # for confusion matrix\n",
    "from sklearn.model_selection import KFold  # for K-fold cross validation\n",
    "from sklearn.model_selection import cross_val_predict  # prediction\n",
    "from sklearn.model_selection import cross_val_score  # score evaluation\n",
    "from sklearn.model_selection import train_test_split  # for split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = traindf.drop(\"Survived\", axis=1)\n",
    "Targeted_feature = traindf[\"Survived\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_features, Targeted_feature, test_size=0.3, random_state=42\n",
    ")\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression  # Logistic Regression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "prediction_lr = model.predict(X_test)\n",
    "print(\"--------------The Accuracy of the model----------------------------\")\n",
    "print(\n",
    "    \"The accuracy of the Logistic Regression is\",\n",
    "    round(accuracy_score(prediction_lr, y_test) * 100, 2),\n",
    ")\n",
    "kfold = KFold(n_splits=10, random_state=22)  # k=10, split the data into 10 equal parts\n",
    "result_lr = cross_val_score(\n",
    "    model, all_features, Targeted_feature, cv=10, scoring=\"accuracy\"\n",
    ")\n",
    "print(\n",
    "    \"The cross validated score for Logistic REgression is:\",\n",
    "    round(result_lr.mean() * 100, 2),\n",
    ")\n",
    "y_pred = cross_val_predict(model, all_features, Targeted_feature, cv=10)\n",
    "sns.heatmap(\n",
    "    confusion_matrix(Targeted_feature, y_pred), annot=True, fmt=\"3.0f\", cmap=\"summer\"\n",
    ")\n",
    "plt.title(\"Confusion_matrix\", y=1.05, size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    criterion=\"gini\",\n",
    "    n_estimators=700,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=\"auto\",\n",
    "    oob_score=True,\n",
    "    random_state=1,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "prediction_rm = model.predict(X_test)\n",
    "print(\"--------------The Accuracy of the model----------------------------\")\n",
    "print(\n",
    "    \"The accuracy of the Random Forest Classifier is\",\n",
    "    round(accuracy_score(prediction_rm, y_test) * 100, 2),\n",
    ")\n",
    "kfold = KFold(n_splits=10, random_state=22)  # k=10, split the data into 10 equal parts\n",
    "result_rm = cross_val_score(\n",
    "    model, all_features, Targeted_feature, cv=10, scoring=\"accuracy\"\n",
    ")\n",
    "print(\n",
    "    \"The cross validated score for Random Forest Classifier is:\",\n",
    "    round(result_rm.mean() * 100, 2),\n",
    ")\n",
    "y_pred = cross_val_predict(model, all_features, Targeted_feature, cv=10)\n",
    "sns.heatmap(\n",
    "    confusion_matrix(Targeted_feature, y_pred), annot=True, fmt=\"3.0f\", cmap=\"summer\"\n",
    ")\n",
    "plt.title(\"Confusion_matrix\", y=1.05, size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machines\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "prediction_svm = model.predict(X_test)\n",
    "print(\"--------------The Accuracy of the model----------------------------\")\n",
    "print(\n",
    "    \"The accuracy of the Support Vector Machines Classifier is\",\n",
    "    round(accuracy_score(prediction_svm, y_test) * 100, 2),\n",
    ")\n",
    "kfold = KFold(n_splits=10, random_state=22)  # k=10, split the data into 10 equal parts\n",
    "result_svm = cross_val_score(\n",
    "    model, all_features, Targeted_feature, cv=10, scoring=\"accuracy\"\n",
    ")\n",
    "print(\n",
    "    \"The cross validated score for Support Vector Machines Classifier is:\",\n",
    "    round(result_svm.mean() * 100, 2),\n",
    ")\n",
    "y_pred = cross_val_predict(model, all_features, Targeted_feature, cv=10)\n",
    "sns.heatmap(\n",
    "    confusion_matrix(Targeted_feature, y_pred), annot=True, fmt=\"3.0f\", cmap=\"summer\"\n",
    ")\n",
    "plt.title(\"Confusion_matrix\", y=1.05, size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=4)\n",
    "model.fit(X_train, y_train)\n",
    "prediction_knn = model.predict(X_test)\n",
    "print(\"--------------The Accuracy of the model----------------------------\")\n",
    "print(\n",
    "    \"The accuracy of the K Nearst Neighbors Classifier is\",\n",
    "    round(accuracy_score(prediction_knn, y_test) * 100, 2),\n",
    ")\n",
    "kfold = KFold(n_splits=10, random_state=22)  # k=10, split the data into 10 equal parts\n",
    "result_knn = cross_val_score(\n",
    "    model, all_features, Targeted_feature, cv=10, scoring=\"accuracy\"\n",
    ")\n",
    "print(\n",
    "    \"The cross validated score for K Nearest Neighbors Classifier is:\",\n",
    "    round(result_knn.mean() * 100, 2),\n",
    ")\n",
    "y_pred = cross_val_predict(model, all_features, Targeted_feature, cv=10)\n",
    "sns.heatmap(\n",
    "    confusion_matrix(Targeted_feature, y_pred), annot=True, fmt=\"3.0f\", cmap=\"summer\"\n",
    ")\n",
    "plt.title(\"Confusion_matrix\", y=1.05, size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "prediction_gnb = model.predict(X_test)\n",
    "print(\"--------------The Accuracy of the model----------------------------\")\n",
    "print(\n",
    "    \"The accuracy of the Gaussian Naive Bayes Classifier is\",\n",
    "    round(accuracy_score(prediction_gnb, y_test) * 100, 2),\n",
    ")\n",
    "kfold = KFold(n_splits=10, random_state=22)  # k=10, split the data into 10 equal parts\n",
    "result_gnb = cross_val_score(\n",
    "    model, all_features, Targeted_feature, cv=10, scoring=\"accuracy\"\n",
    ")\n",
    "print(\n",
    "    \"The cross validated score for Gaussian Naive Bayes classifier is:\",\n",
    "    round(result_gnb.mean() * 100, 2),\n",
    ")\n",
    "y_pred = cross_val_predict(model, all_features, Targeted_feature, cv=10)\n",
    "sns.heatmap(\n",
    "    confusion_matrix(Targeted_feature, y_pred), annot=True, fmt=\"3.0f\", cmap=\"summer\"\n",
    ")\n",
    "plt.title(\"Confusion_matrix\", y=1.05, size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(\n",
    "    criterion=\"gini\", min_samples_split=10, min_samples_leaf=1, max_features=\"auto\"\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "prediction_tree = model.predict(X_test)\n",
    "print(\"--------------The Accuracy of the model----------------------------\")\n",
    "print(\n",
    "    \"The accuracy of the DecisionTree Classifier is\",\n",
    "    round(accuracy_score(prediction_tree, y_test) * 100, 2),\n",
    ")\n",
    "kfold = KFold(n_splits=10, random_state=22)  # k=10, split the data into 10 equal parts\n",
    "result_tree = cross_val_score(\n",
    "    model, all_features, Targeted_feature, cv=10, scoring=\"accuracy\"\n",
    ")\n",
    "print(\n",
    "    \"The cross validated score for Decision Tree classifier is:\",\n",
    "    round(result_tree.mean() * 100, 2),\n",
    ")\n",
    "y_pred = cross_val_predict(model, all_features, Targeted_feature, cv=10)\n",
    "sns.heatmap(\n",
    "    confusion_matrix(Targeted_feature, y_pred), annot=True, fmt=\"3.0f\", cmap=\"summer\"\n",
    ")\n",
    "plt.title(\"Confusion_matrix\", y=1.05, size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model = AdaBoostClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "prediction_adb = model.predict(X_test)\n",
    "print(\"--------------The Accuracy of the model----------------------------\")\n",
    "print(\n",
    "    \"The accuracy of the AdaBoostClassifier is\",\n",
    "    round(accuracy_score(prediction_adb, y_test) * 100, 2),\n",
    ")\n",
    "kfold = KFold(n_splits=10, random_state=22)  # k=10, split the data into 10 equal parts\n",
    "result_adb = cross_val_score(\n",
    "    model, all_features, Targeted_feature, cv=10, scoring=\"accuracy\"\n",
    ")\n",
    "print(\n",
    "    \"The cross validated score for AdaBoostClassifier is:\",\n",
    "    round(result_adb.mean() * 100, 2),\n",
    ")\n",
    "y_pred = cross_val_predict(model, all_features, Targeted_feature, cv=10)\n",
    "sns.heatmap(\n",
    "    confusion_matrix(Targeted_feature, y_pred), annot=True, fmt=\"3.0f\", cmap=\"summer\"\n",
    ")\n",
    "plt.title(\"Confusion_matrix\", y=1.05, size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "model = LinearDiscriminantAnalysis()\n",
    "model.fit(X_train, y_train)\n",
    "prediction_lda = model.predict(X_test)\n",
    "print(\"--------------The Accuracy of the model----------------------------\")\n",
    "print(\n",
    "    \"The accuracy of the LinearDiscriminantAnalysis is\",\n",
    "    round(accuracy_score(prediction_lda, y_test) * 100, 2),\n",
    ")\n",
    "kfold = KFold(n_splits=10, random_state=22)  # k=10, split the data into 10 equal parts\n",
    "result_lda = cross_val_score(\n",
    "    model, all_features, Targeted_feature, cv=10, scoring=\"accuracy\"\n",
    ")\n",
    "print(\n",
    "    \"The cross validated score for AdaBoostClassifier is:\",\n",
    "    round(result_lda.mean() * 100, 2),\n",
    ")\n",
    "y_pred = cross_val_predict(model, all_features, Targeted_feature, cv=10)\n",
    "sns.heatmap(\n",
    "    confusion_matrix(Targeted_feature, y_pred), annot=True, fmt=\"3.0f\", cmap=\"summer\"\n",
    ")\n",
    "plt.title(\"Confusion_matrix\", y=1.05, size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "prediction_gbc = model.predict(X_test)\n",
    "print(\"--------------The Accuracy of the model----------------------------\")\n",
    "print(\n",
    "    \"The accuracy of the Gradient Boosting Classifier is\",\n",
    "    round(accuracy_score(prediction_gbc, y_test) * 100, 2),\n",
    ")\n",
    "kfold = KFold(n_splits=10, random_state=22)  # k=10, split the data into 10 equal parts\n",
    "result_gbc = cross_val_score(\n",
    "    model, all_features, Targeted_feature, cv=10, scoring=\"accuracy\"\n",
    ")\n",
    "print(\n",
    "    \"The cross validated score for AdaBoostClassifier is:\",\n",
    "    round(result_gbc.mean() * 100, 2),\n",
    ")\n",
    "y_pred = cross_val_predict(model, all_features, Targeted_feature, cv=10)\n",
    "sns.heatmap(\n",
    "    confusion_matrix(Targeted_feature, y_pred), annot=True, fmt=\"3.0f\", cmap=\"summer\"\n",
    ")\n",
    "plt.title(\"Confusion_matrix\", y=1.05, size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "We can now rank our evaluation of all the models to choose the best one for our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame(\n",
    "    {\n",
    "        \"Model\": [\n",
    "            \"Support Vector Machines\",\n",
    "            \"KNN\",\n",
    "            \"Logistic Regression\",\n",
    "            \"Random Forest\",\n",
    "            \"Naive Bayes\",\n",
    "            \"AdaBoostClassifier\",\n",
    "            \"Gradient Decent\",\n",
    "            \"Linear Discriminant Analysis\",\n",
    "            \"Decision Tree\",\n",
    "        ],\n",
    "        \"Score\": [\n",
    "            result_svm.mean(),\n",
    "            result_knn.mean(),\n",
    "            result_lr.mean(),\n",
    "            result_rm.mean(),\n",
    "            result_gnb.mean(),\n",
    "            result_adb.mean(),\n",
    "            result_gbc.mean(),\n",
    "            result_lda.mean(),\n",
    "            result_tree.mean(),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "models.sort_values(by=\"Score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at all the matrices, we can say that Random Forest & SVM classifier has a higher chance in correctly predicting dead passengers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-Parameters Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The machine learning models are like a Black-Box. There are some default parameter values for this Black-Box, which we can tune or change the learning rate of the algorithm and get a better model. This is known as Hyper-Parameter Tuning\n",
    "\n",
    "So based on the above given acuracy result i will performance Grid search and random search for the SVM\n",
    "\n",
    " - LDA\n",
    " - Logistic Regression\n",
    " - Gradient Decent Classifier\n",
    " - Random Forest Classifier\n",
    " - Parameters\n",
    "\n",
    "Just a quick summary of the parameters that we will be listing here for completeness,\n",
    "\n",
    " - `n_jobs` : Number of cores used for the training process. If set to -1, all cores are used.\n",
    " - `n_estimators` : Number of classification trees in your learning model ( set to 10 per default)\n",
    " - `max_depth` : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high a number would run the risk of overfitting as one would be growing the tree too deep\n",
    " - `verbose` : Controls whether you want to output any text during the learning process. A value of 0 suppresses all text while a value of 3 outputs the tree learning process at every iteration.\n",
    "\n",
    "Please check out the full description via the official Sklearn website. There you will find that there are a whole host of other useful parameters that you can play around with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = traindf.drop(\"Survived\", axis=1)\n",
    "train_Y = traindf[\"Survived\"]\n",
    "test_X = testdf.drop(\"PassengerId\", axis=1).copy()\n",
    "train_X.shape, train_Y.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "param_grid = {\n",
    "    \"loss\": [\"deviance\"],\n",
    "    \"n_estimators\": [100, 200, 300, 400],\n",
    "    \"learning_rate\": [0.1, 0.05, 0.01, 0.001],\n",
    "    \"max_depth\": [4, 8],\n",
    "    \"min_samples_leaf\": [100, 150],\n",
    "    \"max_features\": [0.3, 0.2, 0.1],\n",
    "}\n",
    "\n",
    "modelf = GridSearchCV(\n",
    "    model, param_grid=param_grid, cv=kfold, scoring=\"accuracy\", n_jobs=4, verbose=1\n",
    ")\n",
    "\n",
    "modelf.fit(train_X, train_Y)\n",
    "\n",
    "# Best score\n",
    "modelf.best_score_\n",
    "\n",
    "# Best Estimator\n",
    "modelf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier Parameters Tunning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier Parameters tunning\n",
    "model = RandomForestClassifier()\n",
    "n_estim = range(100, 1000, 100)\n",
    "\n",
    "## Search grid for optimal parameters\n",
    "param_grid = {\"n_estimators\": n_estim}\n",
    "\n",
    "model_rf = GridSearchCV(\n",
    "    model, param_grid=param_grid, cv=5, scoring=\"accuracy\", n_jobs=4, verbose=1\n",
    ")\n",
    "\n",
    "model_rf.fit(train_X, train_Y)\n",
    "\n",
    "# Best score\n",
    "print(model_rf.best_score_)\n",
    "\n",
    "# best estimator\n",
    "model_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "model = LinearDiscriminantAnalysis()\n",
    "param_grid = {\"tol\": [0.001, 0.01, 0.1, 0.2]}\n",
    "\n",
    "modell = GridSearchCV(\n",
    "    model, param_grid=param_grid, cv=5, scoring=\"accuracy\", n_jobs=4, verbose=1\n",
    ")\n",
    "\n",
    "modell.fit(train_X, train_Y)\n",
    "\n",
    "# Best score\n",
    "print(modell.best_score_)\n",
    "\n",
    "# Best Estimator\n",
    "modell.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC()\n",
    "param_grid = {\n",
    "    \"kernel\": [\"rbf\", \"linear\"],\n",
    "    \"gamma\": [0.001, 0.01, 0.1, 1],\n",
    "    \"C\": [1, 10, 50, 100, 200, 300, 1000],\n",
    "}\n",
    "\n",
    "modelsvm = GridSearchCV(\n",
    "    model, param_grid=param_grid, cv=5, scoring=\"accuracy\", n_jobs=4, verbose=1\n",
    ")\n",
    "\n",
    "modelsvm.fit(train_X, train_Y)\n",
    "\n",
    "print(modelsvm.best_estimator_)\n",
    "\n",
    "# Best score\n",
    "print(modelsvm.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the Estimator which got from parameter tuning of Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=None,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=400,\n",
    "    n_jobs=1,\n",
    "    oob_score=False,\n",
    "    random_state=None,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "random_forest.fit(train_X, train_Y)\n",
    "Y_pred_rf = random_forest.predict(test_X)\n",
    "random_forest.score(train_X, train_Y)\n",
    "acc_random_forest = round(random_forest.score(train_X, train_Y) * 100, 2)\n",
    "\n",
    "print(\"Important features\")\n",
    "pd.Series(random_forest.feature_importances_, train_X.columns).sort_values(\n",
    "    ascending=True\n",
    ").plot.barh(width=0.8)\n",
    "print(\"__\" * 30)\n",
    "print(acc_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(\n",
    "    {\"PassengerId\": test_df[\"PassengerId\"], \"Survived\": Y_pred_rf}\n",
    ")\n",
    "submission.to_csv(\n",
    "    \"data/Titanic - Machine Learning from Disaster/gender_submission.csv\", index=False\n",
    ")\n",
    "print(submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
